{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "April 20_V2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dash pandas\n",
        "!pip install dash==2.0.0\n",
        "!pip install -q jupyter_dash==0.3.0\n",
        "!pip install -q dash-cytoscape\n",
        "!pip install typing-extensions\n",
        "!pip install pandas-datareader\n",
        "!pip install pmdarima\n"
      ],
      "metadata": {
        "id": "OhOsaLeRd-NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_lNwNKzd02p"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import datetime\n",
        "import io\n",
        "\n",
        "from jupyter_dash import JupyterDash\n",
        "from dash import no_update\n",
        "from dash.dependencies import Input, Output, State\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "import dash_table\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import dash\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.tools as tls\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas_datareader as pdr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "import statsmodels.api as sm\n",
        "from pmdarima import auto_arima\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from pandas import to_datetime\n",
        "from prophet import Prophet\n",
        "from matplotlib import pyplot\n",
        "from pandas import DataFrame\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n",
        "from pandas import to_datetime\n",
        "from prophet import Prophet\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parser(s):\n",
        "    return datetime.strptime(s, '%Y-%m-%d')\n",
        "\n",
        "def model_predict(df):\n",
        "  train_size = 0.8\n",
        "  split_idx = round(len(df)* train_size)\n",
        "  train = df.iloc[:split_idx]\n",
        "  test = df.iloc[split_idx:]\n",
        "  \n",
        "  #ARIMA\n",
        "  df = df.iloc[1: , :]\n",
        "  model = sm.tsa.arima.ARIMA(train,order=(1,0,1))\n",
        "  model_fit = model.fit()\n",
        "  modelvalues = model_fit.predict(start=1, end=len(df))\n",
        "  df['Predicted_ARIMA'] = modelvalues.values\n",
        "  predicted_arima = df['Predicted_ARIMA']\n",
        "\n",
        "  #Auto ARIMA\n",
        "  model = auto_arima(train, start_p=0, start_q=0)\n",
        "  forecast = model.predict(n_periods=len(df))\n",
        "  forecast = pd.DataFrame(forecast,index = df.index,columns=['Prediction'])\n",
        "  df['Prediction'] = forecast.values\n",
        "\n",
        "  #SARIMA\n",
        "  model_SARIMA=SARIMAX(train,order=(2,1,0),seasonal_order=(0,1,0,12))\n",
        "  model_SARIMA_fit=model_SARIMA.fit()\n",
        "  modelvalues1 = model_SARIMA_fit.predict(start=1,end=len(df))\n",
        "  df['Predicted_SARIMA']=modelvalues1.values\n",
        "  predicted_sarima = df['Predicted_SARIMA']\n",
        "  residuals=df['Close']-df['Predicted_SARIMA']\n",
        "\n",
        "  #FB PROPHET\n",
        "  df1 = pd.read_csv('LLOYDS_Monthly.csv')\n",
        "  df1.drop(df1.columns.difference(['Date','Close']), 1, inplace=True)\n",
        "  df1.columns = ['ds', 'y']\n",
        "  df1['ds']= to_datetime(df1['ds'])\n",
        "\n",
        "  train_size = 0.8\n",
        "  split_idx = round(len(df1)* train_size)\n",
        "\n",
        "  train1 = df1.iloc[:split_idx]\n",
        "  test1 = df1.iloc[split_idx:]\n",
        "\n",
        "  # define the model\n",
        "  model = Prophet(daily_seasonality=True, weekly_seasonality=True)\n",
        "  # fit the model\n",
        "  model.fit(df1)\n",
        "  forecast_3 = model.predict(test1)\n",
        "  df_past = pd.DataFrame(forecast_3)\n",
        "  # define the period for which we want a prediction\n",
        "  future = list()\n",
        "  for i in range(3,13):\n",
        "      date = '2022-%02d' % i\n",
        "      future.append([date])\n",
        "  future = DataFrame(future)\n",
        "  future.columns = ['ds']\n",
        "  future['ds']= to_datetime(future['ds'])\n",
        "  # use the model to make a forecast\n",
        "  forecast_4 = model.predict(future)\n",
        "  df_future = pd.DataFrame(forecast_4)\n",
        "  # summarize the forecast\n",
        "  #print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']])\n",
        "\n",
        "  return (df, df1, df_past)\n",
        "\n",
        "\n",
        "\n",
        "app = dash.Dash()\n",
        "\n",
        "\n",
        "app.layout = html.Div([\n",
        "    dcc.Upload(\n",
        "        id='upload-data',\n",
        "        children=html.Div([\n",
        "            'Drag and Drop or ',\n",
        "            html.A('Select Files')\n",
        "        ]),\n",
        "        style={\n",
        "            'width': '100%',\n",
        "            'height': '60px',\n",
        "            'lineHeight': '60px',\n",
        "            'borderWidth': '1px',\n",
        "            'borderStyle': 'dashed',\n",
        "            'borderRadius': '5px',\n",
        "            'textAlign': 'center',\n",
        "            'margin': '10px'\n",
        "        },\n",
        "        multiple=False\n",
        "    ),\n",
        "    \n",
        "    \n",
        "    dcc.Graph(id='Mygraph')\n",
        "])\n",
        "\n",
        "\n",
        "def parse_data(contents, filename):\n",
        "    content_type, content_string = contents.split(',')\n",
        "\n",
        "    decoded = base64.b64decode(content_string)\n",
        "    try:\n",
        "        if 'csv' in filename:\n",
        "            # Assume that the user uploaded a CSV file\n",
        "            df = pd.read_csv(io.StringIO(decoded.decode('utf-8')), parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
        "            df.drop(df.columns.difference(['Date','Close']), 1, inplace=True)\n",
        "            df.dropna(inplace = True)\n",
        "            df,df1,df_past=model_predict(df)\n",
        "        elif 'xls' in filename:\n",
        "            # Assume that the user uploaded an excel file\n",
        "            df = pd.read_excel(io.BytesIO(decoded), parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
        "            df.drop(df.columns.difference(['Date','Close']), 1, inplace=True)\n",
        "            df.dropna(inplace = True)\n",
        "            df, df1, df_past = model_predict(df)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return html.Div([\n",
        "            'There was an error processing this file.'\n",
        "        ])\n",
        "    return (df, df1, df_past)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "@app.callback(Output('Mygraph', 'figure'),\n",
        "              [Input('upload-data', 'contents'),\n",
        "              Input('upload-data', 'filename')])\n",
        "\n",
        "def update_graph(contents, filename):\n",
        "    if contents:\n",
        "      contents = contents[0]\n",
        "      filename = filename[0]\n",
        "      df, df1, df_past = parse_data(contents, filename)\n",
        "      figure=go.Figure(data = [go.Scatter(\n",
        "                                        x = df['Date'],\n",
        "                                        y = df['Close'],\n",
        "                                        mode = 'lines',\n",
        "                                        name = 'Observed',\n",
        "                                        line={'color': 'orange'}),\n",
        "                              go.Scatter(\n",
        "                                        x = df['Date'],\n",
        "                                        y = df['Predicted_SARIMA'],\n",
        "                                        mode = 'lines',\n",
        "                                        name = 'Predicted',\n",
        "                                        line={'color': 'green'}),\n",
        "                               ],\n",
        "                                    layout=go.Layout(title={'text':'Close prices Prediction for SARIMA model',\n",
        "                                        'y':0.9,\n",
        "                                        'x':0.5,\n",
        "                                        'xanchor': 'center',\n",
        "                                        'yanchor': 'top'},\n",
        "                                        xaxis_title='Date', \n",
        "                                        yaxis_title='Closing price in pounds (Â£)')\n",
        "                                    )\n",
        "      return figure\n",
        "\n",
        "\n",
        "app.run_server(debug=True, use_reloader=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pudew0EIiIn_",
        "outputId": "902f77d6-3b85-4a48-fd70-4703acca9214"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash is running on http://127.0.0.1:8050/\n",
            "\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: on\n"
          ]
        }
      ]
    }
  ]
}